{"config":{"lang":["en"],"separator":"[\\s\\-]+","pipeline":["stopWordFilter"]},"docs":[{"location":"","title":"Prompt Engineering with watsonx.ai","text":"<p>Welcome! The goals of this workshop are the following:</p> <ul> <li>Gain a comprehensive understanding of prompt engineering</li> <li>Learn techniques to achieve the best results with Large Language Models</li> <li>Apply learnings through completion of a diverse set of prompt engineering exercises</li> </ul>"},{"location":"#about-this-workshop","title":"About this workshop","text":"<p>Part art, part science, prompt engineering is the process of crafting input text to fine-tune a given large language model for best effect.</p> <p>Foundation models have billions of parameters and are trained on terabytes of data to perform a variety of tasks, including text-, code-, or image generation, classification, conversation, and more. A subset known as large language models are used for text- and code-related tasks. When it comes to prompting these models, there isn't just one right answer. There are multiple ways to prompt them for a successful result.</p> <p>In this workshop, you will learn the basics of prompt engineering, from monitoring your token usage to balancing intelligence and security. You will be guided through a range of exercises where you will be able to utilize the different techniques, dials, and levers illustrated in order to get the output you desire from the model. Participants of this workshop will be equipped with a comprehensive understanding of prompt engineering along with the practical skills required to achieve the best results with large language models.</p>"},{"location":"#agenda","title":"Agenda","text":"Lab 0: Pre-work Registration and Setup Lab 1: The Basics of Prompt Engineering Introduction and Examples Lab 2: Go Futher with RAG Retrieval Augmented Generation Lab 3: Apply What You Learned Basic Exercises"},{"location":"#further-study","title":"Further Study","text":"<p>Generative AI: Prompt Engineering Basics by IBM through Coursera</p> <p>Prompt Engineering for Everyone by IBM through CognitiveClass.ai</p> <p></p>"},{"location":"lab-1/","title":"Basics of Prompt Engineering","text":"<p>Note: The following images show actual results from watsonx.ai. The gray text is what we provided to the model. The blue highlighted text is how the model responded.</p>"},{"location":"lab-1/#10-llm-foundations","title":"1.0 LLM Foundations","text":"<p>Before we jump into exploring the capabilities of Prompt Lab, we first need to lay a foundation for how Large Language Models (LLMs) work, and how we can tune the model and parameters to change their output. Gaining this understanding will make us more effective at prompt engineering.</p> <p></p> <p>When you open up Prompt Lab and click the <code>Freeform</code> mode-option, this is what you will be shown. The large central text area is the prompt editor. On the right-side, you can display the model parameters that you can use to select to optimize how the model responds to your prompt. On the bottom-left a summary of the number of tokens used by your prompt during execution will display when we generate a response:</p> <p></p>"},{"location":"lab-1/#11-tokens","title":"1.1 Tokens","text":"<p>Each time you enter a prompt, your input tokens and generated tokens will update. Tokens are an important concept to understand as they constrain the performance of your model plus determine the cost of using models. As you will learn throughout the labs, tokens are not a 1:1 match with words in natural language. On average, one token is equal to 4 characters. Before sending your prompt to the model, the prompt's text is tokenized or broken into smaller subsets of characters better understood by a model.</p> <p>It is important to monitor your token usage to know how much information you are feeding into the model with each prompt, as well as how much text is generated for you. Depending on the model selected in Prompt Lab, you will see a max of 2048 or 4096 tokens. Keep in mind that the more expressive you are with your prompt instructions, the less room the model has to respond back to you.</p>"},{"location":"lab-1/#12-everything-is-text-completion","title":"1.2 Everything is text completion","text":"<p>This is not a chatbot interface (check out the <code>Chat</code> view for that) and with many models, just specifying an instruction or question rarely produces a good result. For instance, what if we prompt the <code>flan-ul2-20b</code> model to list ideas to start some kind of coffee business?</p> <pre><code>Give ideas to start a coffee business\n</code></pre> <p></p> <p>Given our prompt, we were hoping for a little more information; but now we know that simple prompts don't work with all LLMs.</p>"},{"location":"lab-1/#13-cue-the-output-structure","title":"1.3 Cue the output structure","text":"<p>To improve the response, we can start by addressing its structure. Our prompt might imply that we want the ideas in the structure of a list. Let's include a cue to start the response in the desired structure to nudge the model to provide us with a structured response. For example, let's add the two characters <code>1.</code> to the end of our original prompt:</p> <p></p> <p>It might not be perfect, but note how dramatically the response changed and improved just by offering a couple of extra characters to the model.</p>"},{"location":"lab-1/#14-provide-an-example-as-guidance-one-shot-prompting","title":"1.4 Provide an example as guidance (One-Shot Prompting)","text":"<p>Instead of just adding a couple of characters to cue the model, we can provide an entire example before generating. This is called one-shot prompting. Adding even more examples (i.e. few-shot prompting) into your prompt is common practice as well. Generally, increasing the number of examples is a powerful tool to ensure you generate better output.</p> <p>Let's test it out. To receive a higher-quality response, provide an example of the kind of response you want.</p> <pre><code>Give ideas to start a lemonade business:\n1. Set up a lemonade stand\n2. Partner with a restaurant\n3. Arrange for a celebrity to endorse the lemonade\n\nGive ideas to start a coffee business:\n</code></pre> <p></p>"},{"location":"lab-1/#15-include-descriptive-details","title":"1.5 Include descriptive details","text":"<p>Up until now, our prompts have been purposely vague to show the model improving as we improve our prompts. The more guidance, the better. Below, we add more detail to the prompt, such as the number of ideas we want and adjectives describing the business.</p> <pre><code>Give ideas to start a lemonade business:\n1. Set up a lemonade stand\n2. Partner with a restaurant\n3. Arrange for a celebrity to endorse the lemonade\n\nGive me 3 ideas to start my own successful, coffee shop business:\n</code></pre> <p></p> <p>Remember the first, incoherent response we received from this same model? With a few changes to our prompt, the response has improved to become much more coherent and helpful. Below, we'll learn more about all the other tweaks we can make to simple prompts like this to continue to improve the output. </p>"},{"location":"lab-1/#the-model-and-its-parameters","title":"The Model and its Parameters","text":""},{"location":"lab-1/#16-adjusting-the-models-behaviour","title":"1.6 Adjusting the model's behaviour","text":"<p>The first change we can make is the model itself. This is one of the biggest changes you can make, as certain models are better suited for specific tasks. The exercises later on this lab will require you to change the model you use if you want to answer some of the more challenging questions.</p> <p>In general, some models perform better working with summarization, keywords, and semantics, while other models do better with structured text such as HTML, markdown, or JSON. The best way to figure out which models apply for your use case is to simply test them, but it is important to know that choice of model can make a big difference.</p> <p>Prompt Lab also provides multiple parameters for configuring how LLMs respond to a prompt.  Selecting the correct parameters can often be more of an art than a science, but investing time into understanding them will be rewarded by better responses.</p> <p>Explore these parameters using the same text from earlier: <pre><code>Give ideas to start a lemonade business:\n1. Set up a lemonade stand\n2. Partner with a restaurant\n3. Arrange for a celebrity to endorse the lemonade\n\nGive ideas to start a coffee business:\n1.\n</code></pre></p>"},{"location":"lab-1/#17-set-the-min-and-max-tokens","title":"1.7 Set the min and max tokens","text":"<p>If you're finding the generated text is too short or too long, try adjusting the parameters that control the number of new tokens:</p> <ul> <li>The <code>Min tokens</code> parameter controls the minimum number of tokens in the generated response.</li> <li>The <code>Max tokens</code> parameter controls the maximum number of tokens in the generated response.</li> </ul> <p></p>"},{"location":"lab-1/#18-specify-stop-sequences","title":"1.8 Specify stop sequences","text":"<p>If you specify stop sequences, the output will automatically stop when one of them appears in the generated output.</p> <p>The example below (which is using the <code>granite-13b-chat-v2</code> model) shows an output that continues for longer than we want it to.</p> <p></p> <p>To combat this behaviour, we can specify a stop sequence of two carriage returns:</p> <p></p> <p>Now, we have a more satisfying response. The output stops after two carriage returns:</p> <p></p>"},{"location":"lab-1/#19-adjust-decoding-parameters","title":"1.9 Adjust decoding parameters","text":"<p>If the response is too generic or going on wild tangents, consider adjusting the decoding parameters. Or conversely, the response may not be creative and varied enough.</p> <p>Decoding is the process of finding the output sequence given the input sequence:</p> <ul> <li>Greedy decoding selects the word with the highest probability at each step of the decoding process.</li> <li>Sampling decoding selects words from a probability distribution at each step:</li> <li>Temperature refers to selecting high- or low-probability words. Higher temperature values lead to more variability.</li> <li>Top-p (nucleus sampling) refers to selecting the smallest set of words whose cumulative probability exceeds p.</li> <li>Top-k refers to selecting k words with the highest probabilities at each step.  Higher values lead to more variability.</li> </ul> <p>An advantage of greedy decoding is that you will see reproducible results which can be useful for testing. Setting temperature to <code>0</code> in a sampling decoding approach gives the same variance as greedy decoding.</p> <p>Experiment with different parameter values, below is an example of what happens if we switch to the <code>Sampling</code> decoding approach with IBM's <code>granite-13b-chat-v2</code> model: </p> <p></p>"},{"location":"lab-1/#110-add-a-repetition-penalty","title":"1.10 Add a repetition penalty","text":"<p>Sometimes, you will see text being repeated over and over. For example, using the <code>flan-ul2-20b</code> model:</p> <p><code>List ideas to advertise my own successful, coffee shop business:</code></p> <p></p> <p>You could try to increase the temperature to resolve the problem, however, when text is still repetitive, you can also try to add a repetition penalty. The higher the penalty, the less likely the results will include repetitive text:</p> <p></p> <p>When it comes to repetition, remember that sometimes our output requires some. For example, if you wanted a list using bullet points. In that case, penalizing repetition might work against you.</p>"},{"location":"lab-1/#111-additional-reading-on-model-parameters-and-decoding-methods","title":"1.11 Additional reading on model parameters and decoding methods","text":"<ul> <li>Foundation model parameters: decoding and stopping criteria</li> <li>Using different decoding methods</li> </ul>"},{"location":"lab-1/#general-tips","title":"General Tips","text":""},{"location":"lab-1/#112-remember-to-try-different-models","title":"1.12 Remember to try different models","text":"<p>This lab was mainly demonstrated using a model that requires more effort out-of-the-box to highlight the improvements over time. Prompt Lab allows you to easily test many models quickly! The watsonx.ai documentation here lists and describes the available models.</p>"},{"location":"lab-1/#113-understand-your-use-case","title":"1.13 Understand your use case","text":"<p>LLMs have great potential, but they do not have logic, knowledge, or domain expertise. Some use cases are a better fit than others: LLMs excel at tasks that involve generating generic text or common code patterns and transforming given input.</p> <p>If your prompt includes all the tips and best practices discussed here, yet you're not getting satisfactory results from any of the models, take time to consider whether LLMs actually suit your use case. For example, although we can get reasonable results for simple arithmetic, LLMs generally cannot handle math well.</p>"},{"location":"lab-1/#114-balancing-intelligence-and-security","title":"1.14 Balancing intelligence and security","text":"<p>With great artificial intelligence comes higher security risks. Solutions like ChatGPT are known as Very Large language Models (VLLMs) with 175 billion parameters. They are fine-tuned by the OpenAI team using an additional non-public Chat datasets along with Reinforcement Learning Human Feedback (RLHF) dataset. It is a chatbot-enabled LLM.</p> <p>In watsonx.ai, we are interacting directly with smaller LLMs (3-20 billion parameters). This is a wise choice with regard to security. Prompt injection is a major risk for enterprise-use of LLMs. In prompt injections, a hacker will create an intricate prompt in order to cause a LLM such as ChatGPT to ignore/bypass security protocols and reveal sensitive company information.</p> <p>For a moment, imagine you're a hacker. Which model would you choose to target for prompt injection hacking? OpenAI's ChatGPT with 175 billion parameters capable of thousands of tasks or a smaller, more-focused 3 billion parameter model highly tuned for a few isolated tasks?  Which has a larger attack surface for prompt (re-)engineering?</p> <p>The smaller, simpler models in watsonx.ai present a more difficult challenge for potential hackers. Using many small models rather than a single large one such as ChatGPT creates a wider distribution of sensitive entry points. Each small language model is much harder to manipulate due their limited functionality and high level of prompt engineering that was required to perform their primary tasks. They don\u2019t have the wide range of functions a massive LLM would have.  As programmers know, putting all your resources into a single point of failure is unwise. It's far better to decompose your solution for security, scalability, and control.</p>"},{"location":"lab-1/#further-learning","title":"Further learning","text":"<ul> <li>Tips for Writing Foundation Model Prompts: Prompt Engineering</li> <li>watsonx.ai</li> </ul>"},{"location":"lab-2/","title":"Go Further with RAG (Retrieval Augmented Generation)","text":"<p>Note: The following images show actual results from watsonx.ai. The gray text is what we provided to the model. The blue highlighted text is how the model responded.</p>"},{"location":"lab-2/#20-llm-rag","title":"2.0 LLM RAG","text":"<p>RAG (Retrieval-Augmented Generation) is the ability to retrieve facts from an external source to help ground LLMs and provide users detailed or updated information that otherwise might be missing in the LLM. It supplements the LLM's internal representation of information.</p> <p>This has multiple benefits. - Reduces hallucinations - Helps ensure the model has the most current, reliable facts - Reduces the need to continuously retrain LLM models on new data, reducing time and cost</p> <p></p> <p></p>"},{"location":"lab-2/#21-how-to-add-grounding-data","title":"2.1 How to add grounding data:","text":"<p>First, obtain the document you want to add.  You can download the example GitHub issue provided: Issue-36122.pdf</p> <p>Next, click on \"Grounding with documents\" and then click on \"Select or create vector index\" and then \"New vector index\"</p> <p></p> <p>Files can be added in PPTX, DOCX, PDF or TXT format with the following sizes:</p> <pre><code>PPTX: Up to 300 MB\nPDF : Up to 50 MB\nDOCX: Up to 10 MB\nTXT : Up to 5 MB\n</code></pre> <p>Click on \"Browse\" and add the file <code>Issue-36122.pdf</code> you downloaded earlier.</p> <p>Note, the \"Name\" field will auto-fill based on the name of the document you add.</p> <p></p> <p>Click \"Create\".</p> <p>The chat interface then shows that it has the RAG (grounding data) appended as part of the chat:</p> <p></p>"},{"location":"lab-2/#23-using-the-grounding-data","title":"2.3 Using the grounding data","text":"<p>Now, you can ask questions and the grounding data will be used to help complete the answer and will indicate the pages it used from the source.</p> <p>For example, enter \"Please summarize the issue\" and you'll get something like this:</p> <p></p>"},{"location":"lab-2/#24-a-note-about-the-general-chat-feature","title":"2.4 A note about the general chat feature","text":"<p>Unlike exercises where we used Structured or Freeform mode, the Chat page has fewer customizable parameters and the token limits are higher. If you click on \"Edit System Prompt\", you'll see some non-obvious instructions being provided to the LLM:</p> <pre><code>You are Granite Chat, an AI language model developed by IBM. You are a cautious assistant. You carefully follow instructions. You are helpful and harmless and you follow ethical guidelines and promote positive behavior. You are a AI language model designed to function as a specialized Retrieval Augmented Generation (RAG) assistant. When generating responses, prioritize correctness, i.e., ensure that your response is correct given the context and user query, and that it is grounded in the context. Furthermore, make sure that the response is supported by the given document or context. Always make sure that your response is relevant to the question. If an explanation is needed, first provide the explanation or reasoning, and then give the final answer. Avoid repeating information unless asked.\n</code></pre> <p>You can always customize this prompt as needed, but it serves as a good starting point for a well-behaved AI assistant.</p> <p></p>"},{"location":"lab-3/","title":"Apply What You Learned","text":"<p>Complete the following exercises using watsonx.ai's Prompt Lab. </p> <ul> <li>Be curious! Try different, smaller models: do you have to improve your prompt or change parameters to get a satisfactory output?</li> <li>Be creative! Numbered or bulleted list? Feel free to interpret the exercise yourself and make the output look the way you want to.</li> <li>Be specific! Aim for perfection. Use descriptive language, examples, and parameters to perfect your output.</li> </ul> <p>Exercises</p> No. Exercise Summary 1 Generate Write creative sentences 2 Rewrite Transform Markdown to HTML 3 Summarize Summarize a short story 4 Summary Topics List the topics from a meeting transcript 5 Text Extraction Extract verbs from a sentence 6 Compare Identify what passages have in common 7 Text Search Find which page contains the text 8 Classify Detect a users' intent 9 Anomaly Detection Spot the odd entry out 10 Math Question Solve a math question 11 RAG Additional questions for RAG"},{"location":"lab-3/#1-generate","title":"1. Generate","text":"<p>Get a model to output three creative sentences about camels. </p> <p>Can you format the sentences like a list? What happens when you use <code>Sampling</code> decoding and turn <code>temperature</code> up?</p> <p>You can use the examples below to help.</p> <pre><code>3 sentences about puppies:\n- The puppy spun in circles, trying to catch his tail, but ended up tumbling over and over.\n- His antics had his owners laughing out loud, and even the other puppies at the park stopped to watch the silly sight.\n- As soon as the two puppies met at the park, their tails began to wag and they bounded around each other with glee.\n</code></pre> <pre><code>3 sentences about kittens:\n- The little kitten lapped up the milk with her tiny pink tongue, making a cute slurping sound.\n- The kitten nibbled on the treat, savoring every morsel of the delicious flavor.\n- As soon as the package was opened, the little kitten's eyes lit up with excitement.\n</code></pre>  Show example answer"},{"location":"lab-3/#2-rewrite","title":"2. Rewrite","text":"<p>Get a model to output the HTML version of the following Markdown snippets.</p> <p><pre><code>## Background\nThe [IBM Watson Natural Language Processing library](https://dataplatform.cloud.ibm.com/docs/\ncontent/wsj/analyze-data/watson-nlp.html) is a Python library that provides basic natural\nlanguage processing (NLP) such as syntax analysis and keyword extraction with out-of-the-box,\npre-trained models. The Watson NLP library also makes it simple to customize the language\nmodels with dictionaries of your domain-specific terms.\n</code></pre> <pre><code>[MURAL](https://mural.co) is an online tool that is like a virtual whiteboard: you can draw\nshapes, stick notes, and move things around. It\u2019s a fabulous tool for visually organizing ideas,\ndesigning solutions, and collaborating with teammates \u2014 in real time or asynchronously.\n</code></pre> <pre><code>## Function\nUsing LLMs is pretty easy: prompt the model with text (eg. \"I took my dog\") and the model\ngenerates text as output (eg. \"for a walk\").\n</code></pre> <pre><code>## What Are Large Language Models (LLMs)?\n[Large language models](https://www.ibm.com/topics/large-language-models) are AI systems capable of understanding and generating human language by processing vast amounts of text data.\n</code></pre></p> <p>Here's an example of a conversion between Markdown and HTML:</p> <pre><code>Markdown:\n## Welcome to My Blog!\nI'm thrilled to launch my new blog and share my thoughts with you. Expect a wide range of topics including technology, travel, and growth. Stay tuned for engaging and informative posts!\n\nHTML:\n&lt;h2&gt;Welcome to My Blog!&lt;/h2&gt;\n&lt;p&gt;I'm thrilled to launch my new blog and share my thoughts with you. Expect a wide range of topics including technology, travel, and growth. Stay tuned for engaging and informative posts!&lt;/p&gt;\n</code></pre>  Show example answer"},{"location":"lab-3/#3-summarize","title":"3. Summarize","text":"<p>Get a model to output a short one-sentence summary of the following short stories (one at a time).</p> <p><pre><code>Perched on a delicate branch, a tiny sparrow named Luna gazed out at the sunrise, her feathers a fiery hue in the \nmorning light. She trilled a sweet melody, and the forest came alive with the gentle rustle of leaves and chirping \nof her friends. With a flutter of her wings, Luna took to the sky, her heart full of joy and her spirit free.\n</code></pre> <pre><code>Whiskers, a sleek black cat, prowled through the moonlit garden, her ears perked up and her tail twitching with \nexcitement. She stalked her prey, a unsuspecting mouse, with stealthy precision, her eyes gleaming with a fierce \ninner light. With a swift pounce, Whiskers caught her prize, and a triumphant meow echoed through the night air.\n</code></pre> <pre><code>The ship cut through the choppy waves, its sails billowing in the gusty wind as Captain James stood at the helm, \nhis eyes fixed on the horizon. The crew scrambled to secure the deck as a fierce storm brewed, the ship's timbers \ncreaking and groaning beneath their feet. As the storm raged on, the ship rode the turbulent seas, its fate hanging \nin the balance.\n</code></pre> <pre><code>Max, a golden retriever, met Rocky, a black labrador, at the park. They sniffed each other and quickly became friends. \nTogether, they played and had fun in the afternoon. They chased each other around, lapping the playground several times. \nAs the sun began to set, Max and Rocky said their goodbyes, already looking forward to their next adventure together.\n</code></pre></p> <p>Here are some examples to inspire you: <pre><code>Story:\nAs the clock struck midnight, a lone figure crept into the abandoned mansion, their flashlight casting eerie shadows \non the walls. Suddenly, a chill ran down their spine as they stumbled upon a dusty, old portrait of a family, \ntheir eyes seeming to follow them around the room. The figure couldn't shake the feeling that they were being watched, \nand it wasn't until they heard the faint whisper of \"welcome home\" that they realized they weren't alone.\n\nSummary:\nA lone figure uncovers a mysterious presence in an abandoned mansion.\n</code></pre></p> <pre><code>Story:\nAs the door swung open, a chilly gust of air swept into the coffee shop, carrying with it the scent of rain and the \npromise of a new customer. Amal, a regular, strode in, shaking the droplets from her umbrella and smiling wearily \nat Emma behind the counter. \"The usual, please,\" she said, slipping onto a stool and letting out a contented sigh as \nthe warm atmosphere enveloped her. Emma nodded, already reaching for the French roast beans, and began to brew a fresh \ncup.\n\nSummary:\nAmal enters a coffee shop on a rainy day and orders her usual coffee.\n</code></pre>  Show example answer"},{"location":"lab-3/#4-summary-topics","title":"4. Summary Topics","text":"<p>Prompt a model to create a bulleted list of topics from any of the following meeting transcripts. </p> <p><pre><code>00:00 [joe] The goal today is to finalize the budget proposal.\n00:15 [sarah] I think we should allocate 30% to marketing.\n00:30 [joe] That's a good starting point.\n00:50 [dave] I agree, but we should also consider allocating 20% to research and development.\n01:15 [sarah] That's a good point. What about the remaining 50%?\n01:40 [dave] We could use it for operational costs.\n02:05 [joe] I think that's a solid plan. Are we all in agreement?\n02:30 [sarah] Yes, I am.\n02:50 [dave] Me too.\n03:15 [joe] Done!\n</code></pre> <pre><code>00:00 [jess] Let's plan the company picnic!\n00:10 [ali] How about we have it at the beach?\n00:21 [sarah] Good idea.\n00:35 [ali] Can we have a BBQ and games too?\n00:50 [jess] Maybe we could also have a potluck?\n01:05 [sarah] That way everyone can bring something to share.\n01:20 [ali] We could also set up a few outdoor activities like volleyball and badminton.\n01:40 [jess] I like this plan. Let's make it happen!\n</code></pre></p> <p>Here's an example: <pre><code>Transcript:\n00:00 [jane] What's the status on Project A?\n00:15 [bob] We're still waiting on the Johnson report for Project B.\n00:30 [jane] Can we get an update on the timeline for Project C?\n00:45 [bob] I'll send out an email with the latest information.\n01:02 [jane] Also, let's schedule a meeting with the marketing team to discuss the campaign for Project D.\n01:18 [bob] I'll set it up for next Thursday.\n01:35 [jane] Sounds good. Let's move forward with the plan.\n\nSummary:\n- Project A is waiting on Project B\n- Project C update will be emailed\n- Project D will be discussed next Thursday\n</code></pre></p>  Show example answer"},{"location":"lab-3/#5-text-extraction","title":"5. Text Extraction","text":"<p>Extract only the verbs from any of the following sentences.</p> <p>Can you make the model extract only the present tense conjugation verb? (e.g. <code>pounce</code> instead of <code>pounced</code>) </p> <p><pre><code>I will run, jump, and dance to the music festival tonight.\n</code></pre> <pre><code>Their colleagues gathered around the water cooler, and soon discovered that they had much in common, connecting over their shared passion for music and travel.\n</code></pre> <pre><code>As soon as the package was opened, the little cat's eyes lit up with excitement.\n</code></pre> <pre><code>She pounced on the new toy, batting it around the room with joyous abandon.\n</code></pre></p> <p>Here are a couple of examples:</p> <pre><code>Sentence:\nAs soon as the two dogs met at the park, their tails began to wag and they bounded around each other with glee.\nVerbs:\nmet, begin, wag, bound\n\nSentence:\nTheir owners struck up a conversation, and soon found that they had much in common,\nbonding over their shared love of dogs and the outdoors.\nVerbs:\nstrike, found, bond\n</code></pre>  Show example answer"},{"location":"lab-3/#6-compare","title":"6. Compare","text":"<p>Identify what any of the pairs of passages below have in common.</p> <p>You can start by listing common elements (e.g. a bird, the wind), but what about common themes? (e.g. the beauty of the sun) </p> <p><pre><code>The bird sat on the windowsill, its bright feathers a splash of color\nagainst the drab gray wall. It cocked its head to one side, as if listening\nto the distant chirping of its fellow birds. The morning sunlight\nstreamed through the window, casting a warm glow over the bird's\nplumage.\n\nThe bird took to the skies, its wings beating rapidly as it soared above\nthe treetops. The wind ruffled its feathers, but it flew with ease, its eyes\nscanning the landscape below for signs of food or danger. The sun was\nhigh overhead, casting a warm glow over the bird's feathers as it flew\nover the fields and forests.\n</code></pre> <pre><code>It's windy as the sun sets over the horizon, casting a warm glow on the \nlandscape.\n\nA gentle breeze rustles the leaves of the trees as the sun begins to set \nand colour the landscape.\n</code></pre> <pre><code>\"The dog wagged its tail excitedly as it waited for its owner to come\nhome. It had been a long day, and the dog was eager to play and receive\nsome attention. As soon as it heard the door open, the dog ran to greet\nits owner, tail wagging furiously.\"\n\n\"The dog lay on its bed, panting softly as it watched its owner pack\nup the car. It had been a long day, and the dog was tired but content.\nAs soon as its owner gave it a pat and a treat, the dog settled in for a\nwell-deserved nap.\"\n</code></pre> <pre><code>\"The old woman sat on the beach, watching the sun set over the ocean. He\nthought about his life, and the memories he had made with his loved ones.\nAs the stars began to twinkle in the sky, he felt a sense of peace wash over\nhim, knowing that he had lived a full and happy life.\"\n\n\"The old woman sat on the mountain, watching the sun rise over the\nvalley. She thought about her life, and the lessons she had learned from her\nexperiences. As the mist cleared from the valley, she felt a sense of\ncontentment, knowing that she had lived a life of purpose and meaning.\"\n</code></pre></p>  Show example answer"},{"location":"lab-3/#7-text-search","title":"7. Text Search","text":"<p>Get the model to output the page number that contains the text you give it.</p> <p>Start simple and format the output however you like. For a challenge, can you get the model to find words that appear on multiple pages?</p> <pre><code>Page 1: \"A little bird chirped as she gathered twigs and bits of moss in her beak, flitting back and forth between the trees.\"\nPage 2: \"With each trip, her nest took shape, becoming cozier and more inviting.\"\nPage 3: \"And soon enough, she had created a snug home to raise her brood of chirping chicks.\"\nPage 4: \"As the sun began to rise, casting a warm glow over the forest, the little bird sang a sweet lullaby to her chicks.\"\nPage 5: \"The chicks fluttered around their mother, their tiny voices joining in harmony with her own.\"\nPage 6: \"Together, they spent the day exploring the forest, playing and growing stronger by the minute.\"\n</code></pre> <p>Example output: <pre><code>Search term: cozier\nPage: 2\n\nSearch term: enough\nPage: 3\n</code></pre></p> <p>Here's an example input you can build upon:  <pre><code>Story:\nPage 1: \"The wolf walked with purpose, his powerful legs taking him through the snowy terrain.\"\nPage 2: \"He scanned the landscape, his keen eyes searching for any sign of prey or danger.\"\nPage 3: \"The moon's glow illuminated his path, casting long, dancing shadows on the frozen ground.\"\n\nTerm: wolf\nPage: 1\n\nTerm: keen\nPage: 2\n</code></pre></p>  Show example answer"},{"location":"lab-3/#8-classify","title":"8. Classify","text":"<p>Prompt a model to classify the users' intent like a chatbot would. </p> <p>An intent is similar to a user's high-level goal during a conversation. Can the model classify the intent of a user's message? </p> <p>Here are some examples of intent classes:</p> <p>Class: <code>hi</code> <pre><code>Hello\n\nHi there\n\nGood evening\n\nHi\n\nHi good morning\n</code></pre></p> <p>Class: <code>question</code> <pre><code>Hi I wanted to know how to export data from python notebooks?\n\nHi there can i recover a deleted notebook?\n\nHi how do you add a folder of files to a project?\n\nHi team How can you change the name of a Notebook?\n\nHow to upload a dataset from local to RStudio\n\nGood morning can you help me upload a shapefile?\n\nHow to start creating R notebook?\n</code></pre></p> <p>Class: <code>problem</code> <pre><code>Hi cant login today with this err The owners accout is not active. This might be caused by expired membership.\n\nI am not able to register my account need your help\n\nHi I got the message failed to prepare Object-Storage. Would you please give me a suggestion. Thank you.\n\nHi I am trying to request a new API access key but I dont know what the ID should be for me\n\nWhen I try to add a model to any project I get an Unauthorized error.\n</code></pre></p> <p>Below are extra input examples: <pre><code>Hi  Anyone there?\n</code></pre> <pre><code>Having issues setup WML service\n</code></pre> <pre><code>Hi team how can i import data into a project?\n</code></pre></p>  Show example answer"},{"location":"lab-3/#9-anomaly-detection","title":"9. Anomaly Detection","text":"<p>Get the model to spot the odd entry out in any the following datasets. </p> <p>Start by just identifying the outlier, then try to get the model to tell you both the name and its entry number. </p> <p><pre><code>1: \"donkey\"\n2: \"donkey\"\n3: \"kitten\"\n4: \"donkey\"\n5: \"donkey\"\n6: \"donkey\"\n</code></pre> <pre><code>1: \"cat\"\n2: \"cat\"\n3: \"cat\"\n4: \"cat\"\n5: \"dog\"\n6: \"cat\"\n</code></pre> <pre><code>1: \"mouse\"\n2: \"mouse\"\n3: \"mouse\"\n4: \"rat\"\n5: \"mouse\"\n6: \"mouse\"\n</code></pre></p>  Show example answer"},{"location":"lab-3/#10-math-question","title":"10. Math Question","text":"<p>Prompt the model to deduce the answer to the question: how many minutes are there in a day?</p>  Show example answer"},{"location":"lab-3/#11-rag","title":"11. RAG","text":"<p>What additional questions can be included for the example RAG issue? <pre><code>Conclusions that can be deduced from the issue\nNext set of actions to make progress on the issue\nA list of the key stakeholders and owners involved with the issue\nAny risks and dependencies related to the GitHub issue\nAn ETA for delivery from the GitHub issue\n</code></pre></p> <p>Feel free to add your own PPTX (max of 300MB), PDF (max of 50MB), DOCX (max of 10MB), or TXT files (max of 5MB) as grounding data and experiement with your own questions.</p> <p></p>"},{"location":"pre-work/","title":"Pre-work","text":"<p>Let's get prepare our environment to work through the Prompt Engineering lab.</p> <ol> <li>Connect to IBM watsonx.ai</li> <li>Create a sandbox project</li> </ol>"},{"location":"pre-work/#1-connect-to-watsonxai","title":"1. Connect to watsonx.ai","text":"<p>Go to watsonx.ai, click \"Start your free trial\", and follow the instructions to either create an IBM Cloud account or login using a previously made one. </p> <p>You'll be able to use your free trial for this lab and further self-study, just be mindful of token limits as they vary by pricing tier.</p> <p></p> <p>If you recently accessed an account, the platform may tell you that you are already logged in. Confirm your email address, and click the word <code>here</code>.</p> <p></p> <p>Otherwise, click <code>Create an Account or log in</code> and follow the instructions.</p>"},{"location":"pre-work/#2-create-a-sandbox-project-in-watsonxai","title":"2. Create a sandbox project in watsonx.ai","text":"<p>A project is where you work with data and models by using tools. When you sign up for watsonx.ai, your sandbox project is created automatically, and you can start working in it as soon as it's ready. You can also create an empty project, start from a sample project that provides sample data and other assets, or import a previously exported project.</p> <p></p> <p>Once you have a project, you'll be able to open the Prompt Lab, where you can experiment with prompting different foundation models, explore sample prompts, as well as save and share your best prompts.</p> <p></p> <p>Now you're ready to move on to the first lab where we'll cover the basics of prompt engineering and learn how to configure watsonx.ai for the best results.</p>"}]}